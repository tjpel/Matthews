{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c74a4854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Number Of Studios Units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Matthews\\backend\\app\\ai\\v2_model\\vB_fiveParamsLeher-checkpoint.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m validCols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mSize\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNet Income\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mNumber Of Units\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNumber Of Parking Spaces\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTypical Floor (SF)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mNumber Of Studios Units\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNumber Of 1 Bedrooms Units\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNumber Of 2 Bedrooms Units\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mNumber Of 3 Bedrooms Units\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber Of Studios Units\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m columnsInD2)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m mixed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(data2, data1,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                  on \u001b[39m=\u001b[39;49m validCols,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                  how \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mouter\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m merged_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./merged_file.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/v2_model/vB_fiveParamsLeher-checkpoint.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m mixed\u001b[39m.\u001b[39mto_csv(merged_file, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[39m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m rk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39;49m_get_label_or_level_values(rk))\n\u001b[0;32m   1163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[39m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Number Of Studios Units'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv(\"./CostarExport_1.csv\") # getting the data\n",
    "data2 = pd.read_csv(\"./LA_multifamily.csv\") # getting the data\n",
    "\n",
    "columnsInD1 = data1.keys()\n",
    "columnsInD2 = data2.keys()\n",
    "\n",
    "validCols = ['Size', 'Net Income', \n",
    "                     'Number Of Units', 'Number Of Parking Spaces', 'Typical Floor (SF)',\n",
    "                     'Number Of Studios Units', 'Number Of 1 Bedrooms Units', 'Number Of 2 Bedrooms Units',\n",
    "                     'Number Of 3 Bedrooms Units']\n",
    "\n",
    "print('Number Of Studios Units' in columnsInD2)\n",
    "mixed = pd.merge(data2, data1,\n",
    "                 on = validCols,\n",
    "                 how = 'outer')\n",
    "\n",
    "merged_file = './merged_file.csv'\n",
    "\n",
    "mixed.to_csv(merged_file, index = False)\n",
    "pd.DataFrame(mixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2b0222",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sale Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sale Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Matthews\\backend\\app\\ai\\vB_fiveParamsLeher-checkpoint.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m columns_to_clean \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mSale Price\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNet Income\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBuilding SF\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mStar Rating\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPrice Per AC Land\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mPrice Per Unit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDown Payment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSize\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTotal Expense Amount\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mParcel Number 1 (Min)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mParcel Number 2 (Max)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPrice Per SF Land\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns_to_clean:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m$\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Matthews/backend/app/ai/vB_fiveParamsLeher-checkpoint.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m Star\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sale Price'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# cleanup\n",
    "merged_file = r'D:\\Code\\Matthews\\data\\merged_data.csv'\n",
    "df = pd.read_csv(merged_file) \n",
    "\n",
    "columns_to_clean = [\"Sale Price\", \"Net Income\", \"Building SF\", \n",
    "                    \"Star Rating\", \"Price Per AC Land\",\n",
    "                    \"Price Per Unit\", \"Down Payment\", \"Size\", \"Total Expense Amount\",\n",
    "                    'Parcel Number 1 (Min)', 'Parcel Number 2 (Max)', \"Price Per SF Land\"]\n",
    "                    \n",
    "for col in columns_to_clean:\n",
    "    df[col] = df[col].str.replace(',', '')\n",
    "    df[col] = df[col].str.replace('$', '')\n",
    "    df[col] = df[col].str.replace(' Star', '')\n",
    "    df[col] = df[col].str.replace('-', '')\n",
    "    \n",
    "\n",
    "# Convert the columns to numeric\n",
    "df[columns_to_clean] = df[columns_to_clean].apply(pd.to_numeric, errors='coerce')\n",
    "keep = ['Size', 'Building SF', 'Number Of Units', 'Number Of Floors', \n",
    "         'Price Per AC Land', 'Price Per SF Land', 'Asking Price', \n",
    "         'Number Of 1 Bedrooms Units', 'Number Of 2 Bedrooms Units', \n",
    "         'Floor Area Ratio', 'Number Of Parking Spaces', \n",
    "         'Number Of Studios Units', 'Typical Floor (SF)', \n",
    "         'Number Of 3 Bedrooms Units', 'Land Area AC', 'Land Area SF', \n",
    "         'Star Rating', 'Net Income', 'Year Built', 'Age',\n",
    "         'Sale Price']\n",
    "\n",
    "df = df[keep]\n",
    "df.dropna(axis = 0, inplace=True)\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file = '/Users/lehergulati/Downloads/matthews-data-files/cleaned_dataset.csv'\n",
    "df.to_csv(cleaned_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0fcb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Mean Absolute Error: 709779.538525532\n",
      "R-squared: 0.9314609490590121\n",
      "Mean Percentage Error: 27.978595886937757\n",
      "========================================\n",
      "Model: Random Forest\n",
      "Mean Absolute Error: 545259.6971052632\n",
      "R-squared: 0.924536715631016\n",
      "Mean Percentage Error: 16.799344110058755\n",
      "========================================\n",
      "Model: Gradient Boosting\n",
      "Mean Absolute Error: 566635.0208138095\n",
      "R-squared: 0.9341271388117273\n",
      "Mean Percentage Error: 17.312193365916993\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjp00\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MAE: 561723.8727631578, R2: 0.9363583277301212, MPE: 17.286924005305394\n",
      "Gradient Boosting - MAE: 578117.3236018096, R2: 0.9182035906950465, MPE: 17.735956061878692\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# selected_features = ['Building SF', 'Size', 'Net Income', 'Number Of Units', \n",
    "#                      'Number Of Parking Spaces', 'Typical Floor (SF)',\n",
    "#                      'Land Area SF', 'Land Area AC', 'Number Of 2 Bedrooms Units',\n",
    "#                      'Number Of 3 Bedrooms Units', 'Number Of 1 Bedrooms Units']\n",
    "\n",
    "# Building SF                   0.865942    0.184476 -0.184476    0.892998  \n",
    "# Size                          0.865942    0.184476 -0.184476    0.892998  \n",
    "# Net Income                    1.000000    0.259688 -0.259688    0.848735  \n",
    "# Number Of Units               0.757420    0.105807 -0.105807    0.841576  \n",
    "# Number Of Parking Spaces      0.752257    0.221623 -0.221623    0.806509  \n",
    "# Typical Floor (SF)\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "selected_features = ['Size', 'Net Income', \n",
    "                     'Number Of Units', 'Number Of Parking Spaces', 'Typical Floor (SF)',\n",
    "                     'Number Of Studios Units', 'Number Of 1 Bedrooms Units', 'Number Of 2 Bedrooms Units',\n",
    "                     'Number Of 3 Bedrooms Units']\n",
    "# setting train test data\n",
    "\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "df.dropna(axis = 0)\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['Sale Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "\n",
    "# models\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "    ])\n",
    "\n",
    "\n",
    "# run models\n",
    "maes = []\n",
    "for name, model in models.items():\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', model)\n",
    "                              ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    with open(f\"v2_model{name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mpe = np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
    "    maes += [mae]\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "    print(f\"Mean Percentage Error: {mpe}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "X_train_numeric = X_train.drop(columns=non_numeric_columns)\n",
    "X_test_numeric = X_test.drop(columns=non_numeric_columns)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only = 2, include_bias = False)\n",
    "\n",
    "X_poly_train = poly.fit_transform(X_train_numeric)\n",
    "X_poly_test = poly.transform(X_test_numeric)\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "gb = GradientBoostingRegressor(random_state = 42)\n",
    "high_performing_models = {\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gb\n",
    "}\n",
    "\n",
    "for name, model in high_performing_models.items():\n",
    "    model.fit(X_poly_train, y_train)\n",
    "    y_pred = model.predict(X_poly_test)\n",
    "                           \n",
    "    mpe = np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
    "\n",
    "    print(f\"{name} - MAE: {mean_absolute_error(y_test, y_pred)}, R2: {r2_score(y_test, y_pred)}, MPE: {mpe}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916cec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('maes.txt', \"w\") as f:\n",
    "    for mae in maes:\n",
    "        f.write(f\"{mae}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
